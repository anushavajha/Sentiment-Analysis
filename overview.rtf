{\rtf1\ansi\ansicpg1252\deff0\nouicompat{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.18362}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\b\f0\fs28\lang9 Sentiment Analysis with scikit-learn. \par
\b0\fs22 Project Overview:\par


This project performs Sentiment Analysis with scikit-learn by building a logistic regression model to classify movie reviews as either positive or negative. We use the popular IMDB data set and a simple logistic regression estimator from scikit-learn for document classification.

We build and employ a logistic regression classifier using scikit-learn, clean and pre-process text data, perform feature extraction with nltk, tune model hyperparameters and evaluate model accuracy. We apply the logistic regression classification algorithm using scikit-learn and Python to classify movie reviews as either postive or negative.

1. Build and employ a logistic regression classifier using scikit-learn.\par
2. Clean and pre-process text data.\par
3. Perform feature extraction with nltk\par
4. Tune model hyperparameters and evaluate model accuracy\par
Apply the logistic regression classification algorithm using scikit-learn and Python to classify movie reviews as either postive or negative.\par
\par
\b Task 1: Introduction and Importing the Data\line\b0\line Introduction to the data set and the problem overview.\line Import essential modules and helper functions from NumPy, Matplotlib, and scikit-learn.\par
\b Task 2: Transforming Documents into Feature Vectors\b0\line\line Represent text data using the bag-of-words model from natural language processing and information retrieval.\line Construct the vocabulary of the bag-of-words model and transform the provided sample sentences into sparse feature vectors.\par
\b Task 3: Term Frequency-Inverse Document Frequency\par
\b0 In information retrieval and text mining, we often observe words that crop up across our corpus of documents. These words can lead to bad performance during training and test time because they usually don\rquote t contain useful information. \par
Understand and implement a useful statistical technique, Term frequency-inverse document frequency (tf-idf), to downweight these class of words in the feature vector representation. The tf-idf is the product of the term frequency and the inverse document frequency.\par
\b Task 4: Calculate TF-IDF of the Term 'Is'\par
\b0 Manually calculate the tf-idf of an example.\par
Apply scikit-learn\rquote s TfidfTransformer to convert sample text into a vector of tf-idf values and apply the L2-normalization to it.\par
\b Task 5: Data Preparation \par
\b0 Cleaning and pre-processing text data is a vital process in data analysis and especially in natural language processing tasks.\par
Strip the data set of reviews of irrelevant characters including HTML tags, punctuation, and emojis using regular expressions.\par
\b Task 6: Tokenization of Documents\par
\b0 Ensures that k-means image compression is performed only on the slider widget's mouse release events.\par
Repurpose the data preprocessing and k-means clustering logic from previous tasks to operate on images of your choice.\par
Visualize how the image changes as the number of clusters fed to the k-means algorithm is varied.\par
\b Task 7: Document Classification Using Logistic Regression\par
\b0 First, split the data into training and test sets of equal size. Then, create a pipeline to build a logistic regression model.\par
To estimate the best parameters and model, we employ cross-validated grid-search over a parameter grid.\par
\b Task 8: Load Saved Model from Disk\par
\b0 Although the time it takes to train logistic regression models is very little, estimating the best parameters for our model using GridSearchCV can take hours given the size of our training set. \par
In this task,  load a pre-trained model that will later be used to find the best parameter settings, cross validation score, and the test accuracy.\par
\b Task 9: Model Accuracy\par
\b0 In this final task, we take a look at the best parameter settings, cross-validation score, and how well our model classifies the sentiments of reviews it has never seen before from the test set.\par
}
